{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C05d1Z_b1BR0"
      },
      "source": [
        "### 임포트 & 환경설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvgEgmsV1Bou",
        "outputId": "3ac61f89-e1ea-4b63-9c57-488447e17692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"DEVICE:\", DEVICE)\n",
        "\n",
        "# 학습 때 사용한 최대 길이\n",
        "MAX_SEQ_LEN = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2KYUY7t1GrY"
      },
      "source": [
        "### 텍스트 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "eN-CXCRW1G13"
      },
      "outputs": [],
      "source": [
        "# 셀 2:\n",
        "\n",
        "def simple_tokenize(text: str):\n",
        "    \"\"\"\n",
        "    LSTM 학습 때와 최대한 비슷한 규칙으로 토큰화.\n",
        "    필요하면 너가 학습에 썼던 전처리 규칙에 맞춰 조금 수정해도 됨.\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    tokens = re.findall(r\"[a-z0-9']+\", text)\n",
        "    return tokens\n",
        "\n",
        "def encode_text_lstm(text: str, stoi, pad_idx: int, unk_idx: int, max_len: int = MAX_SEQ_LEN, device=DEVICE):\n",
        "    tokens = simple_tokenize(text)\n",
        "    ids = [stoi.get(tok, unk_idx) for tok in tokens][:max_len]\n",
        "    if len(ids) < max_len:\n",
        "        ids += [pad_idx] * (max_len - len(ids))\n",
        "    return torch.tensor(ids, dtype=torch.long).unsqueeze(0).to(device)  # (1, T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqX12oLH1PBp"
      },
      "source": [
        "### LSTM 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri4fNkqQ1NzK",
        "outputId": "be136b68-2bf1-44f8-9791-10111aad6568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LSTM 체크포인트 로드 (epoch=8)\n",
            "장르 개수: 27\n",
            "✅ LSTM high 모델 로드 완료\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sy030\\AppData\\Local\\Temp\\ipykernel_1076\\2622850927.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt_lstm = torch.load(LSTM_MODEL_PATH, map_location=DEVICE)\n"
          ]
        }
      ],
      "source": [
        "LSTM_MODEL_PATH = \"model/lstm.pt\"\n",
        "\n",
        "assert os.path.exists(LSTM_MODEL_PATH), f\"LSTM 모델 파일을 찾을 수 없습니다: {LSTM_MODEL_PATH}\"\n",
        "\n",
        "ckpt_lstm = torch.load(LSTM_MODEL_PATH, map_location=DEVICE)\n",
        "\n",
        "best_epoch_lstm = ckpt_lstm[\"epoch\"]\n",
        "model_state_lstm = ckpt_lstm[\"model_state_dict\"]\n",
        "stoi = ckpt_lstm[\"vocab\"][\"stoi\"]\n",
        "itos = ckpt_lstm[\"vocab\"][\"itos\"]\n",
        "genre_to_idx = ckpt_lstm[\"genre_to_idx\"]\n",
        "idx_to_genre = ckpt_lstm[\"idx_to_genre\"]\n",
        "config_lstm = ckpt_lstm[\"config\"]\n",
        "\n",
        "print(f\"✅ LSTM 체크포인트 로드 (epoch={best_epoch_lstm})\")\n",
        "print(\"장르 개수:\", config_lstm[\"num_labels\"])\n",
        "\n",
        "EMBED_DIM   = config_lstm[\"embed_dim\"]\n",
        "HIDDEN_DIM  = config_lstm[\"hidden_dim\"]\n",
        "NUM_LAYERS  = config_lstm[\"num_layers\"]\n",
        "BIDIRECTIONAL = config_lstm[\"bidirectional\"]\n",
        "NUM_LABELS  = config_lstm[\"num_labels\"]\n",
        "PAD_IDX     = config_lstm[\"pad_idx\"]\n",
        "MAX_SEQ_LEN = config_lstm[\"max_seq_len\"]\n",
        "\n",
        "DROPOUT     = 0.4\n",
        "UNK_IDX     = stoi.get(\"<unk>\", 0)\n",
        "\n",
        "class LSTMTextClassifier(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        embed_dim: int,\n",
        "        hidden_dim: int,\n",
        "        num_layers: int,\n",
        "        num_labels: int,\n",
        "        dropout: float = 0.0,\n",
        "        bidirectional: bool = False,\n",
        "        pad_idx: int = 0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embed_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        factor = 2 if bidirectional else 1\n",
        "        self.fc = nn.Linear(hidden_dim * factor, num_labels)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        emb = self.embedding(input_ids)      # (B, T, E)\n",
        "        output, _ = self.lstm(emb)          # (B, T, H * num_directions)\n",
        "        last_hidden = output[:, -1, :]      # 마지막 타임스텝\n",
        "        last_hidden = self.dropout(last_hidden)\n",
        "        logits = self.fc(last_hidden)       # (B, num_labels)\n",
        "        return logits\n",
        "\n",
        "VOCAB_SIZE = max(stoi.values()) + 1  # stoi가 0~N-1 구조라고 가정\n",
        "\n",
        "lstm_model = LSTMTextClassifier(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embed_dim=EMBED_DIM,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    num_labels=NUM_LABELS,\n",
        "    dropout=DROPOUT,\n",
        "    bidirectional=BIDIRECTIONAL,\n",
        "    pad_idx=PAD_IDX,\n",
        ").to(DEVICE)\n",
        "\n",
        "lstm_model.load_state_dict(model_state_lstm)\n",
        "lstm_model.eval()\n",
        "\n",
        "print(\"✅ LSTM 모델 로드 완료\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dae16162",
        "outputId": "b1558053-7530-470e-8b6e-5add87b54ed8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LSTM V8 체크포인트 로드 (epoch=9)\n",
            "장르 개수: 27\n",
            "✅ LSTM low 모델 로드 완료\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sy030\\AppData\\Local\\Temp\\ipykernel_1076\\3302551344.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt_lstm_v8 = torch.load(LSTM_MODEL_PATH_V8, map_location=DEVICE)\n"
          ]
        }
      ],
      "source": [
        "LSTM_MODEL_PATH_CW = \"model/lstm_CW.pt\"\n",
        "\n",
        "assert os.path.exists(LSTM_MODEL_PATH_CW), f\"LSTM CW 모델 파일을 찾을 수 없습니다: {LSTM_MODEL_PATH_CW}\"\n",
        "\n",
        "ckpt_lstm_CW = torch.load(LSTM_MODEL_PATH_CW, map_location=DEVICE)\n",
        "\n",
        "best_epoch_lstm_CW = ckpt_lstm_CW[\"epoch\"]\n",
        "model_state_lstm_CW = ckpt_lstm_CW[\"model_state_dict\"]\n",
        "stoi_CW = ckpt_lstm_CW[\"vocab\"][\"stoi\"]\n",
        "itos_CW = ckpt_lstm_CW[\"vocab\"][\"itos\"]\n",
        "genre_to_idx_CW = ckpt_lstm_CW[\"genre_to_idx\"]\n",
        "idx_to_genre_CW = ckpt_lstm_CW[\"idx_to_genre\"]\n",
        "config_lstm_CW = ckpt_lstm_CW[\"config\"]\n",
        "\n",
        "print(f\"✅ LSTM CW 체크포인트 로드 (epoch={best_epoch_lstm_CW})\")\n",
        "print(\"장르 개수:\", config_lstm_CW[\"num_labels\"])\n",
        "\n",
        "EMBED_DIM_CW   = config_lstm_CW[\"embed_dim\"]\n",
        "HIDDEN_DIM_CW  = config_lstm_CW[\"hidden_dim\"]\n",
        "NUM_LAYERS_CW  = config_lstm_CW[\"num_layers\"]\n",
        "BIDIRECTIONAL_CW = config_lstm_CW[\"bidirectional\"]\n",
        "NUM_LABELS_CW  = config_lstm_CW[\"num_labels\"]\n",
        "PAD_IDX_CW     = config_lstm_CW[\"pad_idx\"]\n",
        "MAX_SEQ_LEN_CW_MODEL = config_lstm_CW[\"max_seq_len\"]\n",
        "\n",
        "DROPOUT_CW     = 0.4\n",
        "UNK_IDX_CW     = stoi_CW.get(\"<unk>\", 0)\n",
        "\n",
        "VOCAB_SIZE_CW = max(stoi_CW.values()) + 1\n",
        "\n",
        "lstm_model_CW = LSTMTextClassifier(\n",
        "    vocab_size=VOCAB_SIZE_CW,\n",
        "    embed_dim=EMBED_DIM_CW,\n",
        "    hidden_dim=HIDDEN_DIM_CW,\n",
        "    num_layers=NUM_LAYERS_CW,\n",
        "    num_labels=NUM_LABELS_CW,\n",
        "    dropout=DROPOUT_CW,\n",
        "    bidirectional=BIDIRECTIONAL_CW,\n",
        "    pad_idx=PAD_IDX_CW,\n",
        ").to(DEVICE)\n",
        "\n",
        "lstm_model_CW.load_state_dict(model_state_lstm_CW)\n",
        "lstm_model_CW.eval()\n",
        "\n",
        "print(\"✅ LSTM CW 모델 로드 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIX0apU41XfW"
      },
      "source": [
        "### LSTM 예측 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHCmpnOt1WwL",
        "outputId": "d8e1917c-3be1-4f3c-f9c4-d99be77ff114"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LSTM high 테스트]\n",
            "입력: A young boy discovers he has magical powers and attends a school for wizards.\n",
            "예측 장르: comedy (confidence=0.118)\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def predict_genre_lstm(text: str, model, stoi_vocab, pad_idx_val, unk_idx_val, max_len_val, idx_to_genre_map, device=DEVICE):\n",
        "    \"\"\"\n",
        "    LSTM 모델로 영화 줄거리를 입력받아 장르를 예측.\n",
        "    return: (pred_label(str), confidence(float))\n",
        "    \"\"\"\n",
        "    input_ids = encode_text_lstm(\n",
        "        text,\n",
        "        stoi=stoi_vocab,\n",
        "        pad_idx=pad_idx_val,\n",
        "        unk_idx=unk_idx_val,\n",
        "        max_len=max_len_val,\n",
        "        device=device,\n",
        "    )\n",
        "    logits = model(input_ids)\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    pred_id = int(torch.argmax(probs, dim=-1).item())\n",
        "    conf = float(probs[0, pred_id].item())\n",
        "    pred_label = idx_to_genre_map[pred_id]\n",
        "    return pred_label, conf\n",
        "\n",
        "# 간단 테스트 (기존 LSTM 모델 사용)\n",
        "example = \"A young boy discovers he has magical powers and attends a school for wizards.\"\n",
        "label, conf = predict_genre_lstm(\n",
        "    example,\n",
        "    model=lstm_model,\n",
        "    stoi_vocab=stoi,\n",
        "    pad_idx_val=PAD_IDX,\n",
        "    unk_idx_val=UNK_IDX,\n",
        "    max_len_val=MAX_SEQ_LEN,\n",
        "    idx_to_genre_map=idx_to_genre,\n",
        "    device=DEVICE\n",
        ")\n",
        "print(\"[LSTM high 테스트]\")\n",
        "print(\"입력:\", example)\n",
        "print(\"예측 장르:\", label, f\"(confidence={conf:.3f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ExYKZxo1bLJ"
      },
      "source": [
        "### BERT 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ-47zK01aYr",
        "outputId": "43f84bb0-48ba-4c69-aa66-1c1c77af27c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ BERT 모델 / 토크나이저 로드 완료: model/bert_base_full\n",
            "BERT 클래스 수: 27\n",
            "예시 라벨 매핑: [(0, 'action'), (1, 'adult'), (2, 'adventure'), (3, 'animation'), (4, 'biography')]\n"
          ]
        }
      ],
      "source": [
        "BERT_SAVE_DIR = \"model/bert\"\n",
        "\n",
        "assert os.path.exists(BERT_SAVE_DIR), f\"BERT 저장 폴더를 찾을 수 없습니다: {BERT_SAVE_DIR}\"\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(BERT_SAVE_DIR)\n",
        "bert_model = AutoModelForSequenceClassification.from_pretrained(BERT_SAVE_DIR)\n",
        "bert_model.to(DEVICE)\n",
        "bert_model.eval()\n",
        "\n",
        "print(\"✅ BERT 모델 / 토크나이저 로드 완료:\", BERT_SAVE_DIR)\n",
        "\n",
        "# id2label 정리 (int 인덱스로 접근)\n",
        "raw_id2label = bert_model.config.id2label  # {'0': 'Action', '1': 'Comedy', ...} 또는 {0: 'Action', ...}\n",
        "\n",
        "id2label_bert = {}\n",
        "for k, v in raw_id2label.items():\n",
        "    try:\n",
        "        idx = int(k)\n",
        "    except Exception:\n",
        "        idx = k\n",
        "    id2label_bert[idx] = v\n",
        "\n",
        "NUM_LABELS_BERT = len(id2label_bert)\n",
        "print(\"BERT 클래스 수:\", NUM_LABELS_BERT)\n",
        "print(\"예시 라벨 매핑:\", list(id2label_bert.items())[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXkouYXh1fWR"
      },
      "source": [
        "### BERT 예측 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39pTWyus1emL",
        "outputId": "01a7c364-2b87-4411-9691-5f8129f0d42d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BERT 테스트]\n",
            "입력: A young boy discovers he has magical powers and attends a school for wizards.\n",
            "예측 장르: fantasy (confidence=0.331)\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def predict_genre_bert(text: str):\n",
        "    \"\"\"\n",
        "    BERT 모델로 영화 줄거리를 입력받아 장르를 예측.\n",
        "    return: (pred_label(str), confidence(float))\n",
        "    \"\"\"\n",
        "    enc = bert_tokenizer(\n",
        "        text,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=MAX_SEQ_LEN,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
        "\n",
        "    outputs = bert_model(**enc)\n",
        "    logits = outputs.logits              # (1, num_labels)\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    pred_id = int(torch.argmax(probs, dim=-1).item())\n",
        "    conf = float(probs[0, pred_id].item())\n",
        "    pred_label = id2label_bert[pred_id]\n",
        "    return pred_label, conf\n",
        "\n",
        "# 간단 테스트\n",
        "example = \"A young boy discovers he has magical powers and attends a school for wizards.\"\n",
        "label, conf = predict_genre_bert(example)\n",
        "print(\"[BERT 테스트]\")\n",
        "print(\"입력:\", example)\n",
        "print(\"예측 장르:\", label, f\"(confidence={conf:.3f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il5k1MRT1kpE"
      },
      "source": [
        "### 예측 (LSTM / BERT 선택)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo-qqVpb1jDc",
        "outputId": "59ffe91f-4542-4ee0-ec28-5fd2b1af3bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 영화 줄거리 -> 장르 예측 ---\n",
            "사용할 모델을 선택하고, 영화 줄거리를 입력하면 장르를 예측합니다.\n",
            "모델: 'lstm_high', 'lstm_low' 또는 'bert'\n",
            "종료: 모델에서 'quit' 또는 빈 줄\n",
            "\n",
            "사용할 모델 선택 (lstm_high / lstm_low / bert, 종료: quit): lstm_high\n",
            "[LSTM_HIGH] 영화 줄거리 입력 (종료: 빈 줄): Jack, a free-spirited painter, falls in love at first sight with Rose. A passionate love story.\n",
            "→ 예측 장르: comedy (confidence=0.118)\n",
            "\n",
            "[LSTM_HIGH] 영화 줄거리 입력 (종료: 빈 줄): \n",
            "[LSTM_HIGH] 입력 종료.\n",
            "\n",
            "사용할 모델 선택 (lstm_high / lstm_low / bert, 종료: quit): lstm_low\n",
            "[LSTM_LOW] 영화 줄거리 입력 (종료: 빈 줄): Jack, a free-spirited painter, falls in love at first sight with Rose. A passionate love story.\n",
            "→ 예측 장르: comedy (confidence=0.075)\n",
            "\n",
            "[LSTM_LOW] 영화 줄거리 입력 (종료: 빈 줄): \n",
            "[LSTM_LOW] 입력 종료.\n",
            "\n",
            "사용할 모델 선택 (lstm_high / lstm_low / bert, 종료: quit): bert\n",
            "[BERT] 영화 줄거리 입력 (종료: 빈 줄): Jack, a free-spirited painter, falls in love at first sight with Rose. A passionate love story.\n",
            "→ 예측 장르: drama (confidence=0.815)\n",
            "\n",
            "[BERT] 영화 줄거리 입력 (종료: 빈 줄): \n",
            "[BERT] 입력 종료.\n",
            "\n",
            "사용할 모델 선택 (lstm_high / lstm_low / bert, 종료: quit): \n",
            "종료합니다.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- 영화 줄거리 -> 장르 예측 ---\")\n",
        "print(\"사용할 모델을 선택하고, 영화 줄거리를 입력하면 장르를 예측합니다.\")\n",
        "print(\"모델: 'lstm', 'lstm_CW' 또는 'bert'\")\n",
        "print(\"종료: 모델에서 'quit' 또는 빈 줄\\n\")\n",
        "\n",
        "while True:\n",
        "    model_choice = input(\"사용할 모델 선택 (lstm / lstm_CW / bert, 종료: quit): \").strip().lower()\n",
        "    if model_choice in (\"quit\", \"exit\", \"\"):\n",
        "        print(\"종료합니다.\")\n",
        "        break\n",
        "    if model_choice not in (\"lstm\", \"lstm_CW\", \"bert\"):\n",
        "        print(\"❗ 잘못된 입력입니다. 'lstm', 'lstm_CW' 또는 'bert' 중 하나를 입력하세요.\\n\")\n",
        "        continue\n",
        "\n",
        "    while True:\n",
        "        text = input(f\"[{model_choice.upper()}] 영화 줄거리 입력 (종료: 빈 줄): \").strip()\n",
        "        if text == \"\":\n",
        "            print(f\"[{model_choice.upper()}] 입력 종료.\\n\")\n",
        "            break\n",
        "\n",
        "        if model_choice == \"lstm\":\n",
        "            label, conf = predict_genre_lstm(\n",
        "                text,\n",
        "                model=lstm_model,\n",
        "                stoi_vocab=stoi,\n",
        "                pad_idx_val=PAD_IDX,\n",
        "                unk_idx_val=UNK_IDX,\n",
        "                max_len_val=MAX_SEQ_LEN,\n",
        "                idx_to_genre_map=idx_to_genre,\n",
        "                device=DEVICE\n",
        "            )\n",
        "        elif model_choice == \"lstm_CW\":\n",
        "            label, conf = predict_genre_lstm(\n",
        "                text,\n",
        "                model=lstm_model_CW,\n",
        "                stoi_vocab=stoi_CW,\n",
        "                pad_idx_val=PAD_IDX_CW,\n",
        "                unk_idx_val=UNK_IDX_CW,\n",
        "                max_len_val=MAX_SEQ_LEN_CW_MODEL,\n",
        "                idx_to_genre_map=idx_to_genre_CW,\n",
        "                device=DEVICE\n",
        "            )\n",
        "        else: # bert\n",
        "            label, conf = predict_genre_bert(text)\n",
        "\n",
        "        print(f\"→ 예측 장르: {label} (confidence={conf:.3f})\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
